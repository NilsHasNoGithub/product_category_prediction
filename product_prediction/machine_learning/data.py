from io import BytesIO
from pathlib import Path
from typing import Callable, Optional, Tuple, Union

import albumentations as A
import numpy as np
import PIL.Image as pil_img
import torch
import torchvision.transforms as T
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from torch.utils.data.dataset import Dataset, Subset

from ..definitions import RANDOM_STATE
from ..utils import base64_decode, json_load


def create_albumentation_aug_fn(
    albu_aug: A.BaseCompose,
) -> Callable[[pil_img.Image], pil_img.Image]:
    """Wrapper to apply to albumentations pipeline such that it can be applied on pillow images directly"""
    def aug_fn(img: pil_img.Image, aug_=albu_aug) -> pil_img.Image:
        np_img = np.array(img)
        auged_img = aug_(image=np_img)["image"]
        return pil_img.fromarray(auged_img)

    return aug_fn


class VisionProductCategoryDataset(Dataset):
    """Vision dataset for predicting product categories, based on data generated by `create_ml_dataset.py`"""

    def __init__(
        self,
        data_dir: Path,
        transform: Optional[Callable[[pil_img.Image], torch.Tensor]] = None,
        augmentation: Optional[Callable[[pil_img.Image], pil_img.Image]] = None,
    ) -> None:
        super().__init__()

        # Simply turn image into tensor if no transform is provided
        if transform is None:
            transform = T.ToTensor()

        self._data_dir = data_dir
        self._transform = transform
        self._augmentation = augmentation

        self._sample_paths = list(data_dir.glob("**/*.json"))
        assert len(self._sample_paths) > 0, "Expect at least some samples"

        self._raw_labels = []

        for p in self._sample_paths:
            self._raw_labels.append(json_load(p)["category"])

        self._label_encoder = LabelEncoder()
        self._labels = self._label_encoder.fit_transform(self._raw_labels)

    def clone(self) -> "VisionProductCategoryDataset":
        return VisionProductCategoryDataset(
            self._data_dir, self._transform, self._augmentation
        )

    def num_classes(self) -> int:
        return len(self._label_encoder.classes_)

    def label_encoder(self) -> LabelEncoder:
        """Decode integer label to product category"""
        return self._label_encoder

    def set_transform(self, transform: Callable[[pil_img.Image], torch.Tensor]) -> None:
        self._transform = transform

    def set_augmentation(
        self, augmentation: Optional[Callable[[pil_img.Image], pil_img.Image]]
    ) -> None:
        self._augmentation = augmentation

    def __len__(self) -> int:
        return len(self._labels)

    def __getitem__(self, index) -> Tuple[torch.Tensor, int]:
        # Load the json file corresponding to this sample
        sample_dict = json_load(self._sample_paths[index])
        label = self._labels[index]

        # load image from base64
        image = pil_img.open(BytesIO(base64_decode(sample_dict["main_image_base64"])))
        image = image.convert("RGB")

        # augment image if augmentation is provided
        if self._augmentation is not None:
            image = self._augmentation(image)

        image_tensor = self._transform(image)

        return image_tensor, label

    def train_test_split(
        self,
        test_size: Union[int, float] = 0.1,
        stratify: bool = True,
        random_state: int = RANDOM_STATE,
    ) -> Tuple[Subset, Subset]:
        """Create a train and test split of this dataset (deterministic by default)"""
        indices = range(len(self))

        train_indices, test_indices = train_test_split(
            indices,
            test_size=test_size,
            random_state=random_state,
            stratify=self._labels if stratify else None,
        )

        # Make one clone, such that transformations/augmentations can be modified individually
        return Subset(self, train_indices), Subset(self.clone(), test_indices)
